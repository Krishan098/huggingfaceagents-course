{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0150d6",
   "metadata": {},
   "source": [
    "# TOOLS\n",
    "\n",
    "1. FunctionTool: Convert any python function into a tool that the agent can use.\n",
    "\n",
    "2. QueryEngineTool: A tool that lets agents use query engines.\n",
    "\n",
    "3. ToolSpecs: Sets of tools created byt the community, which often include tools for specific services like Gmail.\n",
    "\n",
    "4. Utility Tools: Special tools that help handle large amounts of data from other tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d0cf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting weather for New York\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ToolOutput(content='The weather in New York is sunny.', tool_name='my_weather_tool', raw_input={'args': ('New York',), 'kwargs': {}}, raw_output='The weather in New York is sunny.', is_error=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "def get_weather(location:str)->str:\n",
    "    \"\"\"Useful for getting the weather for a given location.\"\"\"\n",
    "    print(f\"Getting weather for {location}\")\n",
    "    return f\"The weather in {location} is sunny.\"\n",
    "tool=FunctionTool.from_defaults(\n",
    "    get_weather,\n",
    "    name=\"my_weather_tool\",\n",
    "    description=\"useful for getting the weather for a given location.\",\n",
    ")\n",
    "tool.call(\"New York\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96daf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Query Engine tool'''\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "import chromadb\n",
    "embed_model=HuggingFaceEmbedding(\"BAAI/bge-small-en-v1.5\")\n",
    "db=chromadb.PersistentClient(path='./alfred_chroma_db')\n",
    "chroma_collection=db.get_or_create_collection(\"alfred\")\n",
    "vector_store=ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "index=VectorStoreIndex.from_vector_store(vector_store,embed_model=embed_model)\n",
    "llm= HuggingFaceInferenceAPI(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
    "query_engine=index.as_query_engine(llm=llm)\n",
    "tool=QueryEngineTool.from_defaults(query_engine,name=\"query\",description='put up a query and get your answer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28684f14",
   "metadata": {},
   "source": [
    "# Toolspecs\n",
    "\n",
    "- collections of tools that work together like a well organised professional toolkit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24357275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.google import GmailToolSpec\n",
    "tool_spec=GmailToolSpec()\n",
    "tool_spec_list=tool_spec.to_tool_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e336d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('load_data',\n",
       "  \"load_data() -> List[llama_index.core.schema.Document]\\nLoad emails from the user's account.\"),\n",
       " ('search_messages',\n",
       "  \"search_messages(query: str, max_results: Optional[int] = None)\\n\\n        Searches email messages given a query string and the maximum number\\n        of results requested by the user\\n           Returns: List of relevant message objects up to the maximum number of results.\\n\\n        Args:\\n            query (str): The user's query\\n            max_results (Optional[int]): The maximum number of search results\\n            to return.\\n\\n        \"),\n",
       " ('create_draft',\n",
       "  \"create_draft(to: Optional[List[str]] = None, subject: Optional[str] = None, message: Optional[str] = None) -> str\\n\\n        Create and insert a draft email.\\n           Print the returned draft's message and id.\\n           Returns: Draft object, including draft id and message meta data.\\n\\n        Args:\\n            to (Optional[str]): The email addresses to send the message to\\n            subject (Optional[str]): The subject for the event\\n            message (Optional[str]): The message for the event\\n\\n        \"),\n",
       " ('update_draft',\n",
       "  \"update_draft(to: Optional[List[str]] = None, subject: Optional[str] = None, message: Optional[str] = None, draft_id: str = None) -> str\\n\\n        Update a draft email.\\n           Print the returned draft's message and id.\\n           This function is required to be passed a draft_id that is obtained when creating messages\\n           Returns: Draft object, including draft id and message meta data.\\n\\n        Args:\\n            to (Optional[str]): The email addresses to send the message to\\n            subject (Optional[str]): The subject for the event\\n            message (Optional[str]): The message for the event\\n            draft_id (str): the id of the draft to be updated\\n\\n        \"),\n",
       " ('get_draft',\n",
       "  \"get_draft(draft_id: str = None) -> str\\n\\n        Get a draft email.\\n           Print the returned draft's message and id.\\n           Returns: Draft object, including draft id and message meta data.\\n\\n        Args:\\n            draft_id (str): the id of the draft to be updated\\n\\n        \"),\n",
       " ('send_draft',\n",
       "  \"send_draft(draft_id: str = None) -> str\\n\\n        Sends a draft email.\\n           Print the returned draft's message and id.\\n           Returns: Draft object, including draft id and message meta data.\\n\\n        Args:\\n            draft_id (str): the id of the draft to be updated\\n\\n        \")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(tool.metadata.name,tool.metadata.description) for tool in tool_spec_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2b329a",
   "metadata": {},
   "source": [
    "# MCP in LlamaIndex\n",
    "\n",
    "- model context protocol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91471a67",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m mcp_client=BasicMCPClient(\u001b[33m\"\u001b[39m\u001b[33mhttp://127.0.0.1:8000/sse\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m mcp_tool=McpToolSpec(client=mcp_client)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m agent=\u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mget_agent\u001b[49m(mcp_tool)\n\u001b[32m      5\u001b[39m agent_context=Context(agent)\n",
      "\u001b[31mNameError\u001b[39m: name 'get_agent' is not defined"
     ]
    }
   ],
   "source": [
    "from llama_index.tools.mcp import BasicMCPClient,McpToolSpec\n",
    "mcp_client=BasicMCPClient(\"http://127.0.0.1:8000/sse\")\n",
    "mcp_tool=McpToolSpec(client=mcp_client)\n",
    "agent=await get_agent(mcp_tool)\n",
    "agent_context=Context(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4586bc7c",
   "metadata": {},
   "source": [
    "# Utility Tools\n",
    "\n",
    "1. OnDemandToolLoader: This tool turns any existing LlamaIndex data loader into a tool that an agent can use. The tool can be called with all the parameters needed to trigger load_data from the data loader, along with a natural language query string. During execution, we first load data from the data loader, index it and then query it on demand.\n",
    "2. LoadAndSearchToolSpec: It takes in any existing Tool as input. As a tool spec, it implements to_tool_list and when that function is called two tools are returned: a loading tool and then a search tool. The load tool execution would call the underlying Tool, and then index the ouptut. The search tool execution would take in a query string and call the underlying index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4051cf5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777e1b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3231074",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1d66bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
